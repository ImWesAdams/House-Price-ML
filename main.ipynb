{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data from CSV\n",
    "this_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "data_path = os.path.join(this_dir, 'house_data')\n",
    "train = pd.read_csv(data_path + '\\\\train.csv')\n",
    "test = pd.read_csv(data_path + '\\\\test.csv')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          1453\n",
       "MiscFeature     1406\n",
       "Alley           1369\n",
       "Fence           1179\n",
       "MasVnrType       872\n",
       "FireplaceQu      690\n",
       "LotFrontage      259\n",
       "GarageQual        81\n",
       "GarageFinish      81\n",
       "GarageType        81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at prevalence of missing values\n",
    "train.isnull().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the distribution of numeric values a bit\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice       1.000000\n",
       "OverallQual     0.790982\n",
       "GrLivArea       0.708624\n",
       "GarageCars      0.640409\n",
       "GarageArea      0.623431\n",
       "TotalBsmtSF     0.613581\n",
       "1stFlrSF        0.605852\n",
       "FullBath        0.560664\n",
       "TotRmsAbvGrd    0.533723\n",
       "YearBuilt       0.522897\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the numerical variables that correlate most strongly with the Y target\n",
    "train.corr(numeric_only=True)['SalePrice'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Y variable\n",
    "plt.hist(train['SalePrice'], bins=20)\n",
    "plt.title('SalePrice histogram, unadjusted - clear right tail of expensive homes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "# Take the log of saleprice to reduce right skew of housing prices\n",
    "train['SalePrice'] = np.log1p(train['SalePrice'])\n",
    "\n",
    "def clean_columns(df):\n",
    "    # Fill missing numerical values\n",
    "    for col in df.select_dtypes(include='number').columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    # Fill missing object values\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].fillna(\"None\")\n",
    "\n",
    "    # Convert categoricals to 'category' dtype for native handling\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "train = clean_columns(train)\n",
    "\n",
    "X = train.drop('SalePrice', axis=1)\n",
    "y = train[['SalePrice']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "base_X_train, base_X_test, base_y_train, base_y_test = X_train.iloc[:,:].copy(), X_test.iloc[:,:].copy(), y_train.iloc[:,:].copy(), y_test.iloc[:,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot adjusted Y variable\n",
    "plt.hist(y['SalePrice'], bins=20)\n",
    "plt.title('SalePrice histogram, after log - much better!')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE from XGBRegressor = 0.0198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "{'colsample_bytree': 0.7, 'gamma': 0, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.7}\n",
      "0.019779212772846222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>12.209193</td>\n",
       "      <td>200624.0</td>\n",
       "      <td>265972.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>11.798112</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>147684.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>11.608245</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>99707.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>12.165256</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>214761.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>11.385103</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>89722.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>11.350418</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>107724.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>12.552930</td>\n",
       "      <td>282922.0</td>\n",
       "      <td>257380.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>11.856522</td>\n",
       "      <td>141000.0</td>\n",
       "      <td>125193.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>13.521141</td>\n",
       "      <td>745000.0</td>\n",
       "      <td>615515.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>11.910365</td>\n",
       "      <td>148800.0</td>\n",
       "      <td>158231.359375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice         Y           Pred\n",
       "529   12.209193  200624.0  265972.968750\n",
       "491   11.798112  133000.0  147684.546875\n",
       "459   11.608245  110000.0   99707.851562\n",
       "279   12.165256  192000.0  214761.171875\n",
       "655   11.385103   88000.0   89722.976562\n",
       "1013  11.350418   85000.0  107724.156250\n",
       "1403  12.552930  282922.0  257380.312500\n",
       "601   11.856522  141000.0  125193.546875\n",
       "1182  13.521141  745000.0  615515.125000\n",
       "687   11.910365  148800.0  158231.359375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try an XGBoost Regressor since it can handle categoricals and tends to perform pretty well\n",
    "\n",
    "# First get the X and y data from before the model run, just ease of running multiple models on the same data\n",
    "X_train, X_test, y_train, y_test = base_X_train.iloc[:,:].copy(), base_X_test.iloc[:,:].copy(), base_y_train.iloc[:,:].copy(), base_y_test.iloc[:,:].copy()\n",
    "\n",
    "# Model with categoricals enabled\n",
    "model = XGBRegressor(\n",
    "    random_state=0,\n",
    "    enable_categorical=True,\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "# Grid search parameters to try\n",
    "param_grid = {\n",
    "    'n_estimators': [500, 1000],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'subsample': [0.7, 1.0],\n",
    "    'colsample_bytree': [0.7, 1.0],\n",
    "    'gamma': [0, 1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "# Train and retrieve best model\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions and get fit, also output some sample values\n",
    "preds = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(mse)\n",
    "# Get the original non-log price\n",
    "y_test['Y'] = np.expm1(y_test['SalePrice'])\n",
    "# Get the predicted non-log price\n",
    "y_test['Pred'] = np.expm1(preds)\n",
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE from RandomForestRegressor = 0.0200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jwesi\\Documents\\GitHub\\MovieLens-Data-Science\\movielens_env\\lib\\site-packages\\sklearn\\base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressor__max_depth': 20, 'regressor__max_features': 'sqrt', 'regressor__n_estimators': 500}\n",
      "0.02002481516608338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>12.209193</td>\n",
       "      <td>200624.0</td>\n",
       "      <td>214043.231333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>11.798112</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>136648.771238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>11.608245</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>126584.436271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>12.165256</td>\n",
       "      <td>192000.0</td>\n",
       "      <td>202996.339523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>11.385103</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>98356.838488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>11.350418</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>105475.457036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>12.552930</td>\n",
       "      <td>282922.0</td>\n",
       "      <td>233294.781269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>11.856522</td>\n",
       "      <td>141000.0</td>\n",
       "      <td>130698.945683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>13.521141</td>\n",
       "      <td>745000.0</td>\n",
       "      <td>411473.532426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>11.910365</td>\n",
       "      <td>148800.0</td>\n",
       "      <td>157690.864473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice         Y           Pred\n",
       "529   12.209193  200624.0  214043.231333\n",
       "491   11.798112  133000.0  136648.771238\n",
       "459   11.608245  110000.0  126584.436271\n",
       "279   12.165256  192000.0  202996.339523\n",
       "655   11.385103   88000.0   98356.838488\n",
       "1013  11.350418   85000.0  105475.457036\n",
       "1403  12.552930  282922.0  233294.781269\n",
       "601   11.856522  141000.0  130698.945683\n",
       "1182  13.521141  745000.0  411473.532426\n",
       "687   11.910365  148800.0  157690.864473"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try a RandomForestRegressor because why not?\n",
    "\n",
    "# First get the X and y data from before the model run, just ease of running multiple models on the same data\n",
    "X_train, X_test, y_train, y_test = base_X_train.iloc[:,:].copy(), base_X_test.iloc[:,:].copy(), base_y_train.iloc[:,:].copy(), base_y_test.iloc[:,:].copy()\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "# One-hot encode categoricals\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Leave numeric features untouched\n",
    ")\n",
    "\n",
    "# Pipeline with preprocessing and RF model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=0, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Grid search parameters to try, with regressor__ pretag so the Pipeline works properly\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [500, 1000],\n",
    "    'regressor__max_depth': [5, 10, 15, 20],\n",
    "    'regressor__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "# Train and retrieve best model\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions and get fit, also output some sample values\n",
    "preds = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "print(mse)\n",
    "# Get the original non-log price\n",
    "y_test['Y'] = np.expm1(y_test['SalePrice'])\n",
    "# Get the predicted non-log price\n",
    "y_test['Pred'] = np.expm1(preds)\n",
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val MSE: 31.1545\n",
      "Epoch 2, Val MSE: 1.1674\n",
      "Epoch 3, Val MSE: 0.9029\n",
      "Epoch 4, Val MSE: 0.7433\n",
      "Epoch 5, Val MSE: 0.6588\n",
      "Epoch 6, Val MSE: 0.5467\n",
      "Epoch 7, Val MSE: 0.4896\n",
      "Epoch 8, Val MSE: 0.4735\n",
      "Epoch 9, Val MSE: 0.4041\n",
      "Epoch 10, Val MSE: 0.3802\n",
      "Epoch 11, Val MSE: 0.3289\n",
      "Epoch 12, Val MSE: 0.3126\n",
      "Epoch 13, Val MSE: 0.3213\n",
      "Epoch 14, Val MSE: 0.2822\n",
      "Epoch 15, Val MSE: 0.2529\n",
      "Epoch 16, Val MSE: 0.2331\n",
      "Epoch 17, Val MSE: 0.2275\n",
      "Epoch 18, Val MSE: 0.1959\n",
      "Epoch 19, Val MSE: 0.1838\n",
      "Epoch 20, Val MSE: 0.1831\n",
      "Epoch 21, Val MSE: 0.1703\n",
      "Epoch 22, Val MSE: 0.1514\n",
      "Epoch 23, Val MSE: 0.1525\n",
      "Epoch 24, Val MSE: 0.1388\n",
      "Epoch 25, Val MSE: 0.1429\n",
      "Epoch 26, Val MSE: 0.1204\n",
      "Epoch 27, Val MSE: 0.1175\n",
      "Epoch 28, Val MSE: 0.1132\n",
      "Epoch 29, Val MSE: 0.1213\n",
      "Epoch 30, Val MSE: 0.1024\n",
      "Epoch 31, Val MSE: 0.1125\n",
      "Epoch 32, Val MSE: 0.1076\n",
      "Epoch 33, Val MSE: 0.0936\n",
      "Epoch 34, Val MSE: 0.0920\n",
      "Epoch 35, Val MSE: 0.1151\n",
      "Epoch 36, Val MSE: 0.0928\n",
      "Epoch 37, Val MSE: 0.0874\n",
      "Epoch 38, Val MSE: 0.0843\n",
      "Epoch 39, Val MSE: 0.0860\n",
      "Epoch 40, Val MSE: 0.0900\n",
      "Epoch 41, Val MSE: 0.0775\n",
      "Epoch 42, Val MSE: 0.0810\n",
      "Epoch 43, Val MSE: 0.0772\n",
      "Epoch 44, Val MSE: 0.0752\n",
      "Epoch 45, Val MSE: 0.0730\n",
      "Epoch 46, Val MSE: 0.0754\n",
      "Epoch 47, Val MSE: 0.0765\n",
      "Epoch 48, Val MSE: 0.0735\n",
      "Epoch 49, Val MSE: 0.0739\n",
      "Epoch 50, Val MSE: 0.0651\n",
      "Epoch 51, Val MSE: 0.0655\n",
      "Epoch 52, Val MSE: 0.0782\n",
      "Epoch 53, Val MSE: 0.0663\n",
      "Epoch 54, Val MSE: 0.0609\n",
      "Epoch 55, Val MSE: 0.0638\n",
      "Epoch 56, Val MSE: 0.0637\n",
      "Epoch 57, Val MSE: 0.0623\n",
      "Epoch 58, Val MSE: 0.0610\n",
      "Epoch 59, Val MSE: 0.0585\n",
      "Epoch 60, Val MSE: 0.0607\n",
      "Epoch 61, Val MSE: 0.0601\n",
      "Epoch 62, Val MSE: 0.0581\n",
      "Epoch 63, Val MSE: 0.0604\n",
      "Epoch 64, Val MSE: 0.0652\n",
      "Epoch 65, Val MSE: 0.0620\n",
      "Epoch 66, Val MSE: 0.0565\n",
      "Epoch 67, Val MSE: 0.0564\n",
      "Epoch 68, Val MSE: 0.0594\n",
      "Epoch 69, Val MSE: 0.0571\n",
      "Epoch 70, Val MSE: 0.0601\n",
      "Epoch 71, Val MSE: 0.0621\n",
      "Epoch 72, Val MSE: 0.0538\n",
      "Epoch 73, Val MSE: 0.0599\n",
      "Epoch 74, Val MSE: 0.0557\n",
      "Epoch 75, Val MSE: 0.0544\n",
      "Epoch 76, Val MSE: 0.0529\n",
      "Epoch 77, Val MSE: 0.0551\n",
      "Epoch 78, Val MSE: 0.0537\n",
      "Epoch 79, Val MSE: 0.0523\n",
      "Epoch 80, Val MSE: 0.0645\n",
      "Epoch 81, Val MSE: 0.0540\n",
      "Epoch 82, Val MSE: 0.0520\n",
      "Epoch 83, Val MSE: 0.0530\n",
      "Epoch 84, Val MSE: 0.0509\n",
      "Epoch 85, Val MSE: 0.0497\n",
      "Epoch 86, Val MSE: 0.0484\n",
      "Epoch 87, Val MSE: 0.0494\n",
      "Epoch 88, Val MSE: 0.0502\n",
      "Epoch 89, Val MSE: 0.0508\n",
      "Epoch 90, Val MSE: 0.0521\n",
      "Epoch 91, Val MSE: 0.0497\n",
      "Epoch 92, Val MSE: 0.0501\n",
      "Epoch 93, Val MSE: 0.0482\n",
      "Epoch 94, Val MSE: 0.0535\n",
      "Epoch 95, Val MSE: 0.0468\n",
      "Epoch 96, Val MSE: 0.0495\n",
      "Epoch 97, Val MSE: 0.0443\n",
      "Epoch 98, Val MSE: 0.0499\n",
      "Epoch 99, Val MSE: 0.0502\n",
      "Epoch 100, Val MSE: 0.0505\n",
      "Epoch 101, Val MSE: 0.0478\n",
      "Epoch 102, Val MSE: 0.0495\n",
      "Epoch 103, Val MSE: 0.0473\n",
      "Epoch 104, Val MSE: 0.0452\n",
      "Epoch 105, Val MSE: 0.0464\n",
      "Epoch 106, Val MSE: 0.0471\n",
      "Epoch 107, Val MSE: 0.0474\n",
      "Epoch 108, Val MSE: 0.0471\n",
      "Epoch 109, Val MSE: 0.0456\n",
      "Epoch 110, Val MSE: 0.0465\n",
      "Epoch 111, Val MSE: 0.0455\n",
      "Epoch 112, Val MSE: 0.0469\n",
      "Epoch 113, Val MSE: 0.0450\n",
      "Epoch 114, Val MSE: 0.0442\n",
      "Epoch 115, Val MSE: 0.0450\n",
      "Epoch 116, Val MSE: 0.0435\n",
      "Epoch 117, Val MSE: 0.0463\n",
      "Epoch 118, Val MSE: 0.0442\n",
      "Epoch 119, Val MSE: 0.0431\n",
      "Epoch 120, Val MSE: 0.0422\n",
      "Epoch 121, Val MSE: 0.0475\n",
      "Epoch 122, Val MSE: 0.0485\n",
      "Epoch 123, Val MSE: 0.0420\n",
      "Epoch 124, Val MSE: 0.0490\n",
      "Epoch 125, Val MSE: 0.0411\n",
      "Epoch 126, Val MSE: 0.0455\n",
      "Epoch 127, Val MSE: 0.0422\n",
      "Epoch 128, Val MSE: 0.0425\n",
      "Epoch 129, Val MSE: 0.0416\n",
      "Epoch 130, Val MSE: 0.0410\n",
      "Epoch 131, Val MSE: 0.0451\n",
      "Epoch 132, Val MSE: 0.0409\n",
      "Epoch 133, Val MSE: 0.0427\n",
      "Epoch 134, Val MSE: 0.0455\n",
      "Epoch 135, Val MSE: 0.0439\n",
      "Epoch 136, Val MSE: 0.0439\n",
      "Epoch 137, Val MSE: 0.0499\n",
      "Epoch 138, Val MSE: 0.0446\n",
      "Epoch 139, Val MSE: 0.0492\n",
      "Epoch 140, Val MSE: 0.0423\n",
      "Epoch 141, Val MSE: 0.0393\n",
      "Epoch 142, Val MSE: 0.0474\n",
      "Epoch 143, Val MSE: 0.0401\n",
      "Epoch 144, Val MSE: 0.0395\n",
      "Epoch 145, Val MSE: 0.0415\n",
      "Epoch 146, Val MSE: 0.0400\n",
      "Epoch 147, Val MSE: 0.0403\n",
      "Epoch 148, Val MSE: 0.0393\n",
      "Epoch 149, Val MSE: 0.0409\n",
      "Epoch 150, Val MSE: 0.0397\n",
      "Epoch 151, Val MSE: 0.0385\n",
      "Epoch 152, Val MSE: 0.0394\n",
      "Epoch 153, Val MSE: 0.0416\n",
      "Epoch 154, Val MSE: 0.0390\n",
      "Epoch 155, Val MSE: 0.0452\n",
      "Epoch 156, Val MSE: 0.0384\n",
      "Epoch 157, Val MSE: 0.0379\n",
      "Epoch 158, Val MSE: 0.0415\n",
      "Epoch 159, Val MSE: 0.0395\n",
      "Epoch 160, Val MSE: 0.0438\n",
      "Epoch 161, Val MSE: 0.0403\n",
      "Epoch 162, Val MSE: 0.0407\n",
      "Epoch 163, Val MSE: 0.0410\n",
      "Epoch 164, Val MSE: 0.0409\n",
      "Epoch 165, Val MSE: 0.0384\n",
      "Epoch 166, Val MSE: 0.0417\n",
      "Epoch 167, Val MSE: 0.0401\n",
      "Epoch 168, Val MSE: 0.0415\n",
      "Epoch 169, Val MSE: 0.0410\n",
      "Epoch 170, Val MSE: 0.0402\n",
      "Epoch 171, Val MSE: 0.0386\n",
      "Epoch 172, Val MSE: 0.0388\n",
      "Epoch 173, Val MSE: 0.0391\n",
      "Epoch 174, Val MSE: 0.0408\n",
      "Epoch 175, Val MSE: 0.0400\n",
      "Epoch 176, Val MSE: 0.0410\n",
      "Epoch 177, Val MSE: 0.0470\n",
      "Epoch 178, Val MSE: 0.0437\n",
      "Epoch 179, Val MSE: 0.0446\n",
      "Epoch 180, Val MSE: 0.0416\n",
      "Epoch 181, Val MSE: 0.0428\n",
      "Epoch 182, Val MSE: 0.0420\n",
      "Epoch 183, Val MSE: 0.0435\n",
      "Epoch 184, Val MSE: 0.0411\n",
      "Epoch 185, Val MSE: 0.0412\n",
      "Epoch 186, Val MSE: 0.0429\n",
      "Epoch 187, Val MSE: 0.0374\n",
      "Epoch 188, Val MSE: 0.0406\n",
      "Epoch 189, Val MSE: 0.0391\n",
      "Epoch 190, Val MSE: 0.0401\n",
      "Epoch 191, Val MSE: 0.0496\n",
      "Epoch 192, Val MSE: 0.0391\n",
      "Epoch 193, Val MSE: 0.0365\n",
      "Epoch 194, Val MSE: 0.0376\n",
      "Epoch 195, Val MSE: 0.0431\n",
      "Epoch 196, Val MSE: 0.0377\n",
      "Epoch 197, Val MSE: 0.0417\n",
      "Epoch 198, Val MSE: 0.0384\n",
      "Epoch 199, Val MSE: 0.0404\n",
      "Epoch 200, Val MSE: 0.0392\n",
      "Epoch 201, Val MSE: 0.0423\n",
      "Epoch 202, Val MSE: 0.0419\n",
      "Epoch 203, Val MSE: 0.0410\n",
      "Epoch 204, Val MSE: 0.0402\n",
      "Epoch 205, Val MSE: 0.0422\n",
      "Epoch 206, Val MSE: 0.0384\n",
      "Epoch 207, Val MSE: 0.0392\n",
      "Epoch 208, Val MSE: 0.0453\n",
      "Epoch 209, Val MSE: 0.0412\n",
      "Epoch 210, Val MSE: 0.0420\n",
      "Epoch 211, Val MSE: 0.0441\n",
      "Epoch 212, Val MSE: 0.0422\n",
      "Epoch 213, Val MSE: 0.0407\n",
      "Epoch 214, Val MSE: 0.0417\n",
      "Epoch 215, Val MSE: 0.0420\n",
      "Epoch 216, Val MSE: 0.0394\n",
      "Epoch 217, Val MSE: 0.0411\n",
      "Epoch 218, Val MSE: 0.0401\n",
      "Epoch 219, Val MSE: 0.0417\n",
      "Epoch 220, Val MSE: 0.0401\n",
      "Epoch 221, Val MSE: 0.0402\n",
      "Epoch 222, Val MSE: 0.0397\n",
      "Epoch 223, Val MSE: 0.0395\n",
      "Epoch 224, Val MSE: 0.0413\n",
      "Epoch 225, Val MSE: 0.0416\n",
      "Epoch 226, Val MSE: 0.0440\n",
      "Epoch 227, Val MSE: 0.0456\n",
      "Epoch 228, Val MSE: 0.0383\n",
      "Epoch 229, Val MSE: 0.0427\n",
      "Epoch 230, Val MSE: 0.0407\n",
      "Epoch 231, Val MSE: 0.0450\n",
      "Epoch 232, Val MSE: 0.0394\n",
      "Epoch 233, Val MSE: 0.0436\n",
      "Epoch 234, Val MSE: 0.0475\n",
      "Epoch 235, Val MSE: 0.0404\n",
      "Epoch 236, Val MSE: 0.0514\n",
      "Epoch 237, Val MSE: 0.0409\n",
      "Epoch 238, Val MSE: 0.0373\n",
      "Epoch 239, Val MSE: 0.0426\n",
      "Epoch 240, Val MSE: 0.0382\n",
      "Epoch 241, Val MSE: 0.0413\n",
      "Epoch 242, Val MSE: 0.0397\n",
      "Epoch 243, Val MSE: 0.0439\n",
      "Epoch 244, Val MSE: 0.0506\n",
      "Epoch 245, Val MSE: 0.0412\n",
      "Epoch 246, Val MSE: 0.0439\n",
      "Epoch 247, Val MSE: 0.0435\n",
      "Epoch 248, Val MSE: 0.0413\n",
      "Epoch 249, Val MSE: 0.0389\n",
      "Epoch 250, Val MSE: 0.0373\n",
      "0.03731837496161461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.209193</td>\n",
       "      <td>200624.093750</td>\n",
       "      <td>235329.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.798112</td>\n",
       "      <td>133000.000000</td>\n",
       "      <td>147464.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.608245</td>\n",
       "      <td>110000.015625</td>\n",
       "      <td>132881.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.165256</td>\n",
       "      <td>191999.937500</td>\n",
       "      <td>189825.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.385103</td>\n",
       "      <td>87999.976562</td>\n",
       "      <td>79480.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.350418</td>\n",
       "      <td>84999.984375</td>\n",
       "      <td>75200.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.552930</td>\n",
       "      <td>282921.937500</td>\n",
       "      <td>254926.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.856523</td>\n",
       "      <td>141000.046875</td>\n",
       "      <td>128040.523438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.521141</td>\n",
       "      <td>745000.187500</td>\n",
       "      <td>794083.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.910365</td>\n",
       "      <td>148800.000000</td>\n",
       "      <td>154687.718750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice             Y          Pred\n",
       "0  12.209193 200624.093750 235329.640625\n",
       "1  11.798112 133000.000000 147464.859375\n",
       "2  11.608245 110000.015625 132881.078125\n",
       "3  12.165256 191999.937500 189825.500000\n",
       "4  11.385103  87999.976562  79480.109375\n",
       "5  11.350418  84999.984375  75200.843750\n",
       "6  12.552930 282921.937500 254926.203125\n",
       "7  11.856523 141000.046875 128040.523438\n",
       "8  13.521141 745000.187500 794083.937500\n",
       "9  11.910365 148800.000000 154687.718750"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not a lot of data to train on but let's try a neural net anyways!\n",
    "\n",
    "# First get the X and y data from before the model run, just ease of running multiple models on the same data\n",
    "X_train, X_test, y_train, y_test = base_X_train.iloc[:,:].copy(), base_X_test.iloc[:,:].copy(), base_y_train.iloc[:,:].copy(), base_y_test.iloc[:,:].copy()\n",
    "\n",
    "# Separate categorical and numeric columns\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Ordinal encode categoricals with per-column unknown handling\n",
    "cat_dims = []\n",
    "X_train_enc = X_train[cat_cols].copy()\n",
    "X_test_enc = X_test[cat_cols].copy()\n",
    "\n",
    "for col in cat_cols:\n",
    "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=X_train[col].nunique())\n",
    "    X_train_enc[[col]] = encoder.fit_transform(X_train[[col]].astype(str))\n",
    "    X_test_enc[[col]] = encoder.transform(X_test[[col]].astype(str))\n",
    "    cat_dims.append(X_train_enc[col].max() + 1)  # +1 for unknown category\n",
    "\n",
    "X_train[cat_cols] = X_train_enc\n",
    "X_test[cat_cols] = X_test_enc\n",
    "\n",
    "# Normalize numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# Combine all features\n",
    "X_train_processed = X_train[cat_cols + num_cols].copy()\n",
    "X_test_processed = X_test[cat_cols + num_cols].copy()\n",
    "\n",
    "# Define datasets\n",
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, X, y, cat_cols, num_cols):\n",
    "        self.X_cat = torch.tensor(X[cat_cols].values, dtype=torch.long)\n",
    "        self.X_num = torch.tensor(X[num_cols].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_cat[idx], self.X_num[idx], self.y[idx]\n",
    "    \n",
    "train_ds = HouseDataset(X_train_processed, y_train, cat_cols, num_cols)\n",
    "test_ds = HouseDataset(X_test_processed, y_test, cat_cols, num_cols)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define model\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, cat_dims, num_dim):\n",
    "        super().__init__()\n",
    "        # Embed based on the square root of the unique entries in the categorical column\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(cat_dim, min(50, int((cat_dim + 1)  ** 0.5))) for cat_dim in cat_dims\n",
    "        ])\n",
    "        emb_dim = sum([emb.embedding_dim for emb in self.embeddings])\n",
    "        input_dim = emb_dim + num_dim\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm1d(64),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm1d(64),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_cat, x_num):\n",
    "        x = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = torch.cat([x, x_num], dim=1)\n",
    "        return self.net(x)\n",
    "\n",
    "# Define the size of the embeddings based on the unique number of valuables in each categorical column\n",
    "cat_dims = [int(X_train[col].nunique()) + 1 for col in cat_cols]\n",
    "model = NN(cat_dims=cat_dims, num_dim=len(num_cols))\n",
    "\n",
    "# Training (and testing) loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(250):\n",
    "    model.train()\n",
    "    for x_cat, x_num, y in train_loader:\n",
    "        x_cat, x_num, y = x_cat.to(device), x_num.to(device), y.to(device)\n",
    "        preds = model(x_cat, x_num)\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        for x_cat, x_num, y in test_loader:\n",
    "            x_cat, x_num = x_cat.to(device), x_num.to(device)\n",
    "            preds = model(x_cat, x_num).cpu().numpy()\n",
    "            val_preds.extend(preds)\n",
    "            val_targets.extend(y.cpu().numpy()) \n",
    "\n",
    "    val_preds = np.array(val_preds).flatten()\n",
    "    val_targets = np.array(val_targets).flatten()\n",
    "    val_loss = mean_squared_error(val_targets, val_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Val MSE: {val_loss:.4f}\")\n",
    "\n",
    "# Get the predicted values for the full dataframe\n",
    "# Switch model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Collect predictions on test set\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_cat, x_num, y in test_loader:\n",
    "        x_cat, x_num, y = x_cat.to(device), x_num.to(device), y.to(device)\n",
    "        preds = model(x_cat, x_num)\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_targets.append(y.cpu().numpy())\n",
    "\n",
    "# Concatenate and inverse log-transform\n",
    "all_preds = np.vstack(all_preds).flatten()\n",
    "all_targets = np.vstack(all_targets).flatten()\n",
    "\n",
    "# Calculate MSE on original scale\n",
    "mse = mean_squared_error(all_targets, all_preds)\n",
    "print(mse)\n",
    "\n",
    "# Output sample predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'SalePrice': all_targets,\n",
    "    'LogPred': all_preds\n",
    "})\n",
    "\n",
    "# Get the original non-log price\n",
    "results_df['Y'] = np.expm1(results_df['SalePrice'])\n",
    "# Get the predicted non-log price\n",
    "results_df['Pred'] = np.expm1(results_df['LogPred'])\n",
    "\n",
    "# Standardize number format\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "results_df.drop('LogPred', axis=1).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
